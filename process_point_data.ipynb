{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c485e7",
   "metadata": {},
   "source": [
    "# New concept\n",
    "\n",
    "2. Network Graph Model\n",
    "\n",
    "    Analyze:\n",
    "    - How burning \"propagated\" through the graph.\n",
    "    - How graph centrality, degree (number of neighbors), clustering coefficient relate to burn probability.\n",
    "    - Create animation for how spread occured between nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7a8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a097a841",
   "metadata": {},
   "source": [
    "# Prepare Dataset\n",
    "\n",
    "Add columns for `burned_proportion_20m`, `burned_proportion_50m`, `burned_proportion_100m`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff8489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_structures(gpkg_path, layer_name):\n",
    "#     # Load the structures layer\n",
    "#     gdf = gpd.read_file(gpkg_path, layer=layer_name)\n",
    "\n",
    "#     gdf.set_crs(epsg=3857, inplace=True)\n",
    "\n",
    "#     # Reproject to meters if needed\n",
    "#     if not gdf.crs.is_projected:\n",
    "#         raise ValueError(\"CRS must be projected (meters). Please reproject your data first.\")\n",
    "\n",
    "#     # Create a binary \"burned\" column: 1 = Destroyed, 0 = Otherwise\n",
    "#     gdf['burned'] = gdf['DAMAGE'].apply(lambda x: 1 if str(x).lower() == 'destroyed (>50%)' else 0)\n",
    "#     print(\"Unique values:\")\n",
    "#     print(gdf['DAMAGE'].unique())\n",
    "    \n",
    "#     return gdf\n",
    "\n",
    "# def calculate_neighbor_stats(gdf, radii_meters=[20, 50, 100]):\n",
    "#     coords = np.array(list(zip(gdf.geometry.x, gdf.geometry.y)))\n",
    "#     tree = BallTree(coords, metric='euclidean')\n",
    "\n",
    "#     for radius in radii_meters:\n",
    "#         indices = tree.query_radius(coords, r=radius)\n",
    "        \n",
    "#         total_neighbors = []\n",
    "#         burned_neighbors = []\n",
    "#         burned_proportion = []\n",
    "\n",
    "#         burned_array = gdf['burned'].to_numpy()\n",
    "\n",
    "#         for i, neighbors in enumerate(indices):\n",
    "#             neighbors = neighbors[neighbors != i]  # exclude self\n",
    "#             total = len(neighbors)\n",
    "#             burned_count = burned_array[neighbors].sum() if total > 0 else 0\n",
    "\n",
    "#             total_neighbors.append(total)\n",
    "#             burned_neighbors.append(burned_count)\n",
    "#             burned_proportion.append(burned_count / total if total > 0 else 0)\n",
    "\n",
    "#         # Save to GeoDataFrame\n",
    "#         gdf[f'total_neighbors_{radius}m'] = total_neighbors\n",
    "#         gdf[f'burned_neighbors_{radius}m'] = burned_neighbors\n",
    "#         gdf[f'burned_proportion_{radius}m'] = burned_proportion\n",
    "\n",
    "#     return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5104d65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values:\n",
      "['No Damage' 'Destroyed (>50%)' 'Affected (1-9%)' 'Minor (10-25%)'\n",
      " 'Inaccessible' 'Major (26-50%)']\n",
      "Saved enriched structures to data/structures_with_neighbors.gpkg\n"
     ]
    }
   ],
   "source": [
    "# gpkg_file = \"data/structures.gpkg\"\n",
    "# layer_name = \"postfire\"\n",
    "# output_file = \"data/structures_with_neighbors.gpkg\"\n",
    "\n",
    "# # Step 1: Load and preprocess\n",
    "# gdf = preprocess_structures(gpkg_file, layer_name)\n",
    "\n",
    "# # Step 2: Calculate neighbor stats\n",
    "# gdf = calculate_neighbor_stats(gdf, radii_meters=[20, 50, 100])\n",
    "\n",
    "# # Step 3: Save enriched data\n",
    "# gdf.to_file(output_file, driver=\"GPKG\")\n",
    "# print(f\"Saved enriched structures to {output_file}\")\n",
    "\n",
    "# # Step 4: Train a simple logistic regression model\n",
    "# feature_columns = [\n",
    "#     'burned_proportion_20m',\n",
    "#     'burned_proportion_50m',\n",
    "#     'burned_proportion_100m'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a04ba33",
   "metadata": {},
   "source": [
    "# NEW 5/6/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "788e6d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing input data...\n",
      "Unique DAMAGE values in points: ['No Damage' 'Destroyed (>50%)' 'Affected (1-9%)' 'Minor (10-25%)'\n",
      " 'Inaccessible' 'Major (26-50%)']\n",
      "Assigning burned status to polygons...\n",
      "Computing neighbor statistics...\n",
      "Calculating neighbors within 10m...\n",
      "Calculating neighbors within 20m...\n",
      "Calculating neighbors within 50m...\n",
      "Calculating neighbors within 100m...\n",
      "Merging statistics back to centroid points...\n",
      "Saving output GeoPackages...\n",
      "✅ Done.\n",
      "Polygon output saved to: outputs/structures_polygons_with_neighbors_POLY-METHOD.gpkg\n",
      "Point output saved to:   outputs/structures_points_with_neighbors_POLY-METHOD.gpkg\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_inputs(polygon_shapefile, point_gpkg_path, point_layer):\n",
    "    # === Load input layers ===\n",
    "    polys = gpd.read_file(polygon_shapefile)\n",
    "    points = gpd.read_file(point_gpkg_path, layer=point_layer)\n",
    "\n",
    "    # === Set and check projection ===\n",
    "    polys.set_crs(epsg=3857, inplace=True)\n",
    "    points.set_crs(epsg=3857, inplace=True)\n",
    "\n",
    "    for gdf, name in zip([polys, points], ['Polygon layer', 'Point layer']):\n",
    "        if not gdf.crs.is_projected:\n",
    "            raise ValueError(f\"{name} must be projected in meters (e.g., EPSG:3857).\")\n",
    "\n",
    "    # === Create burned field from DAMAGE ===\n",
    "    points['burned'] = points['DAMAGE'].apply(lambda x: 1 if str(x).lower() == 'destroyed (>50%)' else 0)\n",
    "    print(\"Unique DAMAGE values in points:\", points['DAMAGE'].unique())\n",
    "\n",
    "    # === Spatial join: keep only points that fall inside a polygon ===\n",
    "    joined = gpd.sjoin(points, polys[['geometry']], how='inner', predicate='within')\n",
    "    joined = joined.drop(columns=['index_right'])\n",
    "\n",
    "    # === Assign burned values to polygons ===\n",
    "    print(\"Assigning burned status to polygons...\")\n",
    "    polys_with_burned = gpd.sjoin(polys, joined[['geometry', 'burned']], how='left', predicate='contains')\n",
    "    polys_with_burned = polys_with_burned.drop(columns=['index_right'], errors='ignore')\n",
    "    polys_with_burned['burned'] = polys_with_burned['burned'].fillna(0).astype(int)\n",
    "\n",
    "    # === Add unique ID for cross-layer tracking ===\n",
    "    polys_with_burned = polys_with_burned.reset_index(drop=True)\n",
    "    polys_with_burned['uid'] = polys_with_burned.index\n",
    "\n",
    "    joined = joined.reset_index(drop=True)\n",
    "    joined['uid'] = joined.index\n",
    "\n",
    "    return polys_with_burned, joined\n",
    "def calculate_neighbor_stats(polys, radii_meters=[10, 20, 50, 100]):\n",
    "    enriched_polys = polys.copy()\n",
    "\n",
    "    if 'burned' not in enriched_polys.columns:\n",
    "        raise KeyError(\"Missing 'burned' column in polygon input — check preprocessing.\")\n",
    "\n",
    "    for radius in radii_meters:\n",
    "        print(f\"Calculating neighbors within {radius}m...\")\n",
    "\n",
    "        # Buffer geometries\n",
    "        buffered = enriched_polys.copy()\n",
    "        buffered['geometry'] = buffered.geometry.buffer(radius)\n",
    "\n",
    "        # Perform spatial join (burned comes from enriched_polys → RIGHT side)\n",
    "        joined = gpd.sjoin(buffered, enriched_polys, how='left', predicate='intersects')\n",
    "\n",
    "        # Drop self-matches\n",
    "        joined = joined[joined['uid_left'] != joined['uid_right']]\n",
    "\n",
    "        # Use renamed columns (burned_right, uid_right)\n",
    "        if 'burned_right' not in joined.columns:\n",
    "            print(\"Joined columns:\", joined.columns.tolist())\n",
    "            raise KeyError(\"Expected 'burned_right' column missing after spatial join\")\n",
    "\n",
    "        # Aggregate neighbor stats\n",
    "        stats = joined.groupby('uid_left').agg(\n",
    "            total_neighbors=('uid_right', 'count'),\n",
    "            burned_neighbors=('burned_right', 'sum')\n",
    "        ).reindex(enriched_polys['uid'], fill_value=0)\n",
    "\n",
    "        stats['burned_proportion'] = stats['burned_neighbors'] / stats['total_neighbors'].replace(0, np.nan)\n",
    "\n",
    "        # Add to output\n",
    "        enriched_polys[f'total_neighbors_{radius}m'] = stats['total_neighbors'].values\n",
    "        enriched_polys[f'burned_neighbors_{radius}m'] = stats['burned_neighbors'].values\n",
    "        enriched_polys[f'burned_proportion_{radius}m'] = stats['burned_proportion'].fillna(0).values\n",
    "\n",
    "    return enriched_polys\n",
    "\n",
    "\n",
    "def merge_stats_back_to_points(points, enriched_polys):\n",
    "    stat_cols = [col for col in enriched_polys.columns if 'neighbors_' in col or 'proportion' in col]\n",
    "    merged = points.merge(enriched_polys[['uid'] + stat_cols], on='uid', how='left')\n",
    "    return merged\n",
    "\n",
    "# === Input paths ===\n",
    "polygon_shapefile = \"data/clipped_structure_polygons_altadena/clipped_structure_polygons_altadena.shp\"\n",
    "point_gpkg_path = \"data/structures.gpkg\"\n",
    "point_layer = \"POSTFIRE\"\n",
    "\n",
    "# === Output paths ===\n",
    "polygon_output_gpkg = \"outputs/structures_polygons_with_neighbors_POLY-METHOD.gpkg\"\n",
    "point_output_gpkg = \"outputs/structures_points_with_neighbors_POLY-METHOD.gpkg\"\n",
    "\n",
    "# === Main Execution ===\n",
    "print(\"Loading and preprocessing input data...\")\n",
    "polys, points = preprocess_inputs(polygon_shapefile, point_gpkg_path, point_layer)\n",
    "\n",
    "print(\"Computing neighbor statistics...\")\n",
    "enriched_polys = calculate_neighbor_stats(polys, radii_meters=[10, 20, 50, 100])\n",
    "\n",
    "print(\"Merging statistics back to centroid points...\")\n",
    "enriched_points = merge_stats_back_to_points(points, enriched_polys)\n",
    "\n",
    "print(\"Saving output GeoPackages...\")\n",
    "enriched_polys.to_file(polygon_output_gpkg, layer=\"polygons\", driver=\"GPKG\")\n",
    "enriched_points.to_file(point_output_gpkg, layer=\"points\", driver=\"GPKG\")\n",
    "\n",
    "print(\"✅ Done.\")\n",
    "print(f\"Polygon output saved to: {polygon_output_gpkg}\")\n",
    "print(f\"Point output saved to:   {point_output_gpkg}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
