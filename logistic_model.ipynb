{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c485e7",
   "metadata": {},
   "source": [
    "# New concept\n",
    "\n",
    "2. Network Graph Model\n",
    "\n",
    "    Analyze:\n",
    "    - How burning \"propagated\" through the graph.\n",
    "    - How graph centrality, degree (number of neighbors), clustering coefficient relate to burn probability.\n",
    "    - Create animation for how spread occured between nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7a8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a097a841",
   "metadata": {},
   "source": [
    "# Prepare Dataset\n",
    "\n",
    "Add columns for `burned_proportion_20m`, `burned_proportion_50m`, `burned_proportion_100m`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aff8489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_structures(gpkg_path, layer_name):\n",
    "    # Load the structures layer\n",
    "    gdf = gpd.read_file(gpkg_path, layer=layer_name)\n",
    "\n",
    "    gdf.set_crs(epsg=3857, inplace=True)\n",
    "\n",
    "    # Reproject to meters if needed\n",
    "    if not gdf.crs.is_projected:\n",
    "        raise ValueError(\"CRS must be projected (meters). Please reproject your data first.\")\n",
    "\n",
    "    # Create a binary \"burned\" column: 1 = Destroyed, 0 = Otherwise\n",
    "    gdf['burned'] = gdf['DAMAGE'].apply(lambda x: 1 if str(x).lower() == 'destroyed (>50%)' else 0)\n",
    "    print(\"Unique values:\")\n",
    "    print(gdf['DAMAGE'].unique())\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "def calculate_neighbor_stats(gdf, radii_meters=[20, 50, 100]):\n",
    "    coords = np.array(list(zip(gdf.geometry.x, gdf.geometry.y)))\n",
    "    tree = BallTree(coords, metric='euclidean')\n",
    "\n",
    "    for radius in radii_meters:\n",
    "        indices = tree.query_radius(coords, r=radius)\n",
    "        \n",
    "        total_neighbors = []\n",
    "        burned_neighbors = []\n",
    "        burned_proportion = []\n",
    "\n",
    "        burned_array = gdf['burned'].to_numpy()\n",
    "\n",
    "        for i, neighbors in enumerate(indices):\n",
    "            neighbors = neighbors[neighbors != i]  # exclude self\n",
    "            total = len(neighbors)\n",
    "            burned_count = burned_array[neighbors].sum() if total > 0 else 0\n",
    "\n",
    "            total_neighbors.append(total)\n",
    "            burned_neighbors.append(burned_count)\n",
    "            burned_proportion.append(burned_count / total if total > 0 else 0)\n",
    "\n",
    "        # Save to GeoDataFrame\n",
    "        gdf[f'total_neighbors_{radius}m'] = total_neighbors\n",
    "        gdf[f'burned_neighbors_{radius}m'] = burned_neighbors\n",
    "        gdf[f'burned_proportion_{radius}m'] = burned_proportion\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5104d65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values:\n",
      "['No Damage' 'Destroyed (>50%)' 'Affected (1-9%)' 'Minor (10-25%)'\n",
      " 'Inaccessible' 'Major (26-50%)']\n",
      "Saved enriched structures to data/structures_with_neighbors.gpkg\n"
     ]
    }
   ],
   "source": [
    "gpkg_file = \"data/structures.gpkg\"\n",
    "layer_name = \"postfire\"\n",
    "output_file = \"data/structures_with_neighbors.gpkg\"\n",
    "\n",
    "# Step 1: Load and preprocess\n",
    "gdf = preprocess_structures(gpkg_file, layer_name)\n",
    "\n",
    "# Step 2: Calculate neighbor stats\n",
    "gdf = calculate_neighbor_stats(gdf, radii_meters=[20, 50, 100])\n",
    "\n",
    "# Step 3: Save enriched data\n",
    "gdf.to_file(output_file, driver=\"GPKG\")\n",
    "print(f\"Saved enriched structures to {output_file}\")\n",
    "\n",
    "# Step 4: Train a simple logistic regression model\n",
    "feature_columns = [\n",
    "    'burned_proportion_20m',\n",
    "    'burned_proportion_50m',\n",
    "    'burned_proportion_100m'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f18c9",
   "metadata": {},
   "source": [
    "# Logistic Model\n",
    "\n",
    "Note the high precision score of the logistic model, at ~0.90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "051ca464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_model(gdf, features, target='burned'):\n",
    "    # Drop any NaN values if they exist\n",
    "    data = gdf.dropna(subset=features + [target])\n",
    "\n",
    "    X = data[features]\n",
    "    y = data[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)\n",
    "\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"=== Logistic Regression Report ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e012221f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      2687\n",
      "           1       0.89      0.91      0.90      2841\n",
      "\n",
      "    accuracy                           0.89      5528\n",
      "   macro avg       0.89      0.89      0.89      5528\n",
      "weighted avg       0.89      0.89      0.89      5528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_logistic_model(gdf, features=feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf486891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_model_with_pvalues(gdf, features, target='burned'):\n",
    "    # Drop NaNs\n",
    "    data = gdf.dropna(subset=features + [target])\n",
    "\n",
    "    X = data[features]\n",
    "    y = data[target]\n",
    "\n",
    "    # Add a constant (intercept) term manually\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Build logistic model\n",
    "    model = sm.Logit(y, X)\n",
    "    result = model.fit()\n",
    "\n",
    "    # Print the summary\n",
    "    print(result.summary())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b18965d",
   "metadata": {},
   "source": [
    "Note that the p value is less than 0.001 for each of the variables `burned_proportion_20m`, `burned_proportion_50m`, `burned_proportion_100m`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ceceb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273373\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 burned   No. Observations:                18426\n",
      "Model:                          Logit   Df Residuals:                    18422\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sun, 27 Apr 2025   Pseudo R-squ.:                  0.6055\n",
      "Time:                        23:01:42   Log-Likelihood:                -5037.2\n",
      "converged:                       True   LL-Null:                       -12767.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                     -3.4742      0.057    -61.219      0.000      -3.585      -3.363\n",
      "burned_proportion_20m      1.4546      0.067     21.753      0.000       1.324       1.586\n",
      "burned_proportion_50m      3.9796      0.126     31.668      0.000       3.733       4.226\n",
      "burned_proportion_100m     1.9275      0.140     13.771      0.000       1.653       2.202\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = train_logistic_model_with_pvalues(gdf, features=feature_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
